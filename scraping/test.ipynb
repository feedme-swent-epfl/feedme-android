{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing https://en.wikibooks.org/wiki/Cookbook:A_Nice_Cup_of_Tea...\n",
      "https://en.wikibooks.org/wiki/Cookbook:A_Nice_Cup_of_Tea has been processed.\n",
      "Processing https://en.wikibooks.org/wiki/Cookbook:Baked_Penne...\n",
      "https://en.wikibooks.org/wiki/Cookbook:Baked_Penne has been processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vh/qxbx1gcd7xb1gcxc5z2l5nmw0000gn/T/ipykernel_6584/2536064079.py:76: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  difficulty_row = difficulty.find('th', text=lambda text: text and 'Difficulty' in text)\n",
      "/var/folders/vh/qxbx1gcd7xb1gcxc5z2l5nmw0000gn/T/ipykernel_6584/2536064079.py:89: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  servings = soup.find('th', text='Servings').find_next_sibling('td').text if soup.find('th', text='Servings') else 'Not specified'\n",
      "/var/folders/vh/qxbx1gcd7xb1gcxc5z2l5nmw0000gn/T/ipykernel_6584/2536064079.py:111: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  ingredients_list = [li.text.strip() for li in soup.find('span', text='Ingredients').parent.find_next_sibling('ul').find_all('li')] if soup.find('span', text='Ingredients') else []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Dictionary mapping Unicode fraction symbols to their decimal equivalents\n",
    "fraction_mapping = {\n",
    "    '\\u00BD': '1/5',  # 1/2\n",
    "    '\\u00BC': '1/4', # 1/4\n",
    "    '\\u00BE': '3/4', # 3/4\n",
    "    '\\u2153': '1/3', # 1/3\n",
    "    '\\u2154': '2/3', # 2/3\n",
    "    '\\u215b': '1/8', # 1/8\n",
    "    '\\u00b0': 'degrees ', #Â°\n",
    "    '\\u2013': '-', # -\n",
    "    '\\u00a0': ' ' # space\n",
    "    # Add more mappings as needed\n",
    "}\n",
    "\n",
    "def replace_fraction_symbols(text):\n",
    "    # Define a regex pattern that captures numbers possibly adjacent to fraction symbols\n",
    "    pattern = r'(\\d*)(%s)(\\d*)' % '|'.join(re.escape(key) for key in fraction_mapping.keys())\n",
    "\n",
    "    # Function to replace each match with appropriate spacing\n",
    "    def replace(match):\n",
    "        # Pre-number, fraction, and post-number\n",
    "        pre, frac, post = match.groups()\n",
    "        # Replace the fraction with its decimal equivalent from the dictionary\n",
    "        frac_decimal = fraction_mapping[frac]\n",
    "        # Add space if there is a preceding or succeeding number\n",
    "        if frac_decimal == 'degrees ' or frac_decimal == '-' or frac_decimal == ' ':\n",
    "            if pre and post:\n",
    "                return f'{pre} {frac_decimal} {post}'\n",
    "            elif pre:\n",
    "                return f'{pre} {frac_decimal}'\n",
    "            elif post:\n",
    "                return f'{frac_decimal} {post}' \n",
    "        elif pre and post:\n",
    "            return f'{pre} and {frac_decimal} {post}'\n",
    "        elif pre:\n",
    "            return f'{pre} and {frac_decimal}'\n",
    "        elif post:\n",
    "            return f'{frac_decimal} {post}'\n",
    "        return frac_decimal\n",
    "\n",
    "    return re.sub(pattern, replace, text)\n",
    "\n",
    "\n",
    "# Global sets to store unique ingredients and categories\n",
    "all_ingredients = set()\n",
    "all_categories = set()\n",
    "\n",
    "\n",
    "## Scrapes detailed information about a recipe from its page. ##\n",
    "def scrape_recipe_details(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page with BeautifulSoup\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Attempting to extract data based on typical Wikibooks structure\n",
    "        full_title = soup.title.text.replace(\" - Wikibooks, open books for an open world\", \"\").strip()\n",
    "        # Use regex to find everything after \"Cookbook:\"\n",
    "        match = re.search(r'Cookbook:(.*)', full_title)\n",
    "        if match:\n",
    "            title = match.group(1).strip()\n",
    "        else:\n",
    "            title = full_title  # Fallback to the full title if \"Cookbook:\" is not found\n",
    "        difficulty = soup.find('table', class_='infobox')\n",
    "        if difficulty:\n",
    "            difficulty_row = difficulty.find('th', text=lambda text: text and 'Difficulty' in text)\n",
    "            if difficulty_row:\n",
    "                # The difficulty value might be represented by an image alt text\n",
    "                difficulty_image = difficulty_row.find_next_sibling('td').find('img')\n",
    "                if difficulty_image and 'alt' in difficulty_image.attrs:\n",
    "                    difficulty = difficulty_image['alt'].strip()\n",
    "                else:\n",
    "                    difficulty = \"Difficulty image or alt text not found.\"\n",
    "            else:\n",
    "                difficulty = \"Difficulty row not found.\"\n",
    "        else:\n",
    "            difficulty = \"Infobox table not found.\"\n",
    "\n",
    "        servings = soup.find('th', text='Servings').find_next_sibling('td').text if soup.find('th', text='Servings') else 'Not specified'\n",
    "\n",
    "        cooking_time = soup.find('table', class_='infobox')\n",
    "        if cooking_time:\n",
    "            time_row = cooking_time.find('th', string='Time')\n",
    "            if time_row:\n",
    "                time_data = time_row.find_next_sibling('td')\n",
    "                if time_data:\n",
    "                    time_text = time_data.text.strip()\n",
    "                    # Use regex to capture everything after \"Cooking:\"\n",
    "                    match = re.search(r\"Cooking:\\s*(.*)\", time_text)\n",
    "                    if match:\n",
    "                        cooking_time = match.group(1).strip()  # Give only the text after \"Cooking:\"\n",
    "                    else:\n",
    "                        cooking_time = time_text\n",
    "                else:\n",
    "                    cooking_time = \"Cooking time data not found.\"\n",
    "            else:\n",
    "                cooking_time = \"Time row not found.\"\n",
    "        else:\n",
    "            cooking_time = \"Infobox table not found.\"\n",
    "\n",
    "        ingredients_list = [li.text.strip() for li in soup.find('span', text='Ingredients').parent.find_next_sibling('ul').find_all('li')] if soup.find('span', text='Ingredients') else []\n",
    "        \n",
    "        directions_list = soup.find('ol')\n",
    "        if directions_list:\n",
    "            directions_list = [li.text.strip() for li in directions_list.find_all('li')]\n",
    "        else:\n",
    "            directions_list = [\"Procedure section not found.\"]\n",
    "        \n",
    "        categories_elements = [a.text for a in soup.find_all('a', href=True) if 'Category:' in a['href']]\n",
    "        \n",
    "        procedure_span = soup.find('span', string='Procedure')\n",
    "        notes_list = []\n",
    "        if procedure_span and procedure_span.parent:\n",
    "            notes_ul = procedure_span.parent.find_next_sibling('ul')\n",
    "            if notes_ul:\n",
    "                # Find all list item elements within the <ul> and extract their text\n",
    "                notes_list = [li.text.strip() for li in notes_ul.find_all('li')]\n",
    "            if not notes_list:  # If the list is empty, no notes were found\n",
    "                notes_list = ['No notes available']\n",
    "        else:\n",
    "            notes_list = ['No procedure section found.']\n",
    "\n",
    "    recipe_info = {\n",
    "        'title': title,\n",
    "        'level': difficulty,\n",
    "        'yield': servings,\n",
    "        'cooking time': replace_fraction_symbols(cooking_time),\n",
    "        'ingredients': [replace_fraction_symbols(string) for string in ingredients_list], ## TODO: before adding ingredients to recipe info\n",
    "        'steps': [replace_fraction_symbols(string) for string in directions_list],\n",
    "        'cook note': [replace_fraction_symbols(string) for string in notes_list],\n",
    "        'categories': categories_elements\n",
    "    }\n",
    "    \n",
    "    all_ingredients.update(recipe_info['ingredients']) ## TODO: remove the measurments before adding to ingredients\n",
    "    all_categories.update(recipe_info['categories'])\n",
    "    \n",
    "    return recipe_info\n",
    "\n",
    "\n",
    "## Writes data to a JSON file. ##\n",
    "def write_json(data, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "\n",
    "def main():\n",
    "    counter = 0\n",
    "    test_urls = [\"https://en.wikibooks.org/wiki/Cookbook:A_Nice_Cup_of_Tea\", \"https://en.wikibooks.org/wiki/Cookbook:Baked_Penne\"]\n",
    "    recipes = {}\n",
    "    \n",
    "    for url in test_urls:\n",
    "        print(f\"Processing {url}...\")\n",
    "\n",
    "        # Extract information from the recipe\n",
    "        details = scrape_recipe_details(url)\n",
    "        recipes[counter] = details\n",
    "        counter += 1\n",
    "        print(f\"{url} has been processed.\")\n",
    "    \n",
    "    # Writing the index file and ingredient/category accumulations\n",
    "    write_json(recipes, \"recipes.json\")\n",
    "    write_json(list(all_ingredients), \"all_ingredients.json\")\n",
    "    write_json(list(all_categories), \"all_categories.json\")\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
